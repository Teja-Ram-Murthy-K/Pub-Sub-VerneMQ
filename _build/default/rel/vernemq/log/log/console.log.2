2023-02-11 20:18:54.944 [info] <0.222.0>@vmq_swc_peer_service_manager:write_old_actor_to_disk:{180,13} writing (updated) old actor <<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>> to disk
2023-02-11 20:18:54.951 [info] <0.222.0>@vmq_swc_peer_service_manager:write_state_to_disk:{163,13} writing state {[{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}],{dict,1,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[['VerneMQ@127.0.0.1',{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}]],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}},{dict,0,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}}} to disk <<75,2,131,80,0,0,0,247,120,1,203,96,206,97,96,96,96,204,96,130,82,41,12,172,137,201,37,249,69,185,64,81,145,247,235,108,38,154,170,95,47,158,239,182,161,38,224,232,241,31,137,199,152,108,178,18,25,179,50,56,83,24,88,82,50,147,75,18,25,19,5,128,144,35,49,32,209,32,67,32,11,13,100,48,2,197,192,230,130,8,166,20,6,193,176,212,162,188,84,223,64,7,67,35,115,61,3,32,52,36,205,94,116,243,225,206,96,32,232,12,52,173,0,211,246,78,109>>
2023-02-11 20:18:55.315 [info] <0.89.0> alarm_handler: {set,{system_memory_high_watermark,[]}}
2023-02-11 20:18:56.204 [info] <0.228.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta1"
2023-02-11 20:18:56.220 [info] <0.240.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta2"
2023-02-11 20:18:56.223 [info] <0.249.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta3"
2023-02-11 20:18:56.233 [info] <0.258.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta4"
2023-02-11 20:18:56.246 [info] <0.267.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta5"
2023-02-11 20:18:56.253 [info] <0.276.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta6"
2023-02-11 20:18:56.257 [info] <0.285.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta7"
2023-02-11 20:18:56.258 [info] <0.294.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta8"
2023-02-11 20:18:56.260 [info] <0.303.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta9"
2023-02-11 20:18:56.263 [info] <0.312.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta10"
2023-02-11 20:18:56.298 [info] <0.215.0>@vmq_metadata:start:{29,5} Try to start vmq_swc: ok
2023-02-11 20:18:56.345 [info] <0.325.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/1"
2023-02-11 20:18:56.347 [info] <0.326.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/2"
2023-02-11 20:18:56.349 [info] <0.327.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/3"
2023-02-11 20:18:56.350 [info] <0.328.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/4"
2023-02-11 20:18:56.352 [info] <0.329.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/5"
2023-02-11 20:18:56.362 [info] <0.330.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/6"
2023-02-11 20:18:56.373 [info] <0.331.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/7"
2023-02-11 20:18:56.375 [info] <0.332.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/8"
2023-02-11 20:18:56.376 [info] <0.333.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/9"
2023-02-11 20:18:56.384 [info] <0.334.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/10"
2023-02-11 20:18:56.386 [info] <0.335.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/11"
2023-02-11 20:18:56.387 [info] <0.336.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/12"
2023-02-11 20:18:56.551 [info] <0.215.0>@vmq_message_store:start:{29,5} Try to start vmq_generic_msg_store: ok
2023-02-11 20:18:56.654 [info] <0.427.0>@vmq_reg_trie:handle_info:{254,5} loaded 0 subscriptions into vmq_reg_trie
2023-02-11 20:18:56.660 [info] <0.226.0>@vmq_cluster:init:{163,5} cluster event handler 'vmq_cluster' registered
2023-02-11 20:22:57.758 [error] <0.629.0>@ssl_config:file_error:366 CRASH REPORT Process <0.629.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 20:22:57.759 [error] <0.627.0>@ssl_config:file_error:366 Supervisor {<0.627.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.629.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:22:57.760 [error] <0.456.0>@ssl_config:file_error:366 Supervisor {<0.456.0>,ranch_acceptors_sup} had child {acceptor,<0.456.0>,1} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 1, {sslsocket,nil,{#Port<0.12>,{config,#{key => undefined,session_tickets => disabled,handshake => full,...},...}}}, ranch_ssl, logger) at <0.459.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:23:21.426 [error] <0.637.0>@ssl_config:file_error:366 CRASH REPORT Process <0.637.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 20:23:21.427 [error] <0.635.0>@ssl_config:file_error:366 Supervisor {<0.635.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.637.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:23:21.427 [error] <0.456.0>@ssl_config:file_error:366 Supervisor {<0.456.0>,ranch_acceptors_sup} had child {acceptor,<0.456.0>,2} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 2, {sslsocket,nil,{#Port<0.12>,{config,#{key => undefined,session_tickets => disabled,handshake => full,...},...}}}, ranch_ssl, logger) at <0.460.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:23:41.273 [error] <0.655.0>@ssl_config:file_error:366 CRASH REPORT Process <0.655.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 20:23:41.273 [error] <0.653.0>@ssl_config:file_error:366 Supervisor {<0.653.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.655.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:23:41.273 [error] <0.456.0>@ssl_config:file_error:366 Supervisor {<0.456.0>,ranch_acceptors_sup} had child {acceptor,<0.456.0>,3} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 3, {sslsocket,nil,{#Port<0.12>,{config,#{key => undefined,session_tickets => disabled,handshake => full,...},...}}}, ranch_ssl, logger) at <0.461.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:23:51.024 [error] <0.662.0>@ssl_config:file_error:366 CRASH REPORT Process <0.662.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 20:23:51.024 [error] <0.660.0>@ssl_config:file_error:366 Supervisor {<0.660.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.662.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:23:51.025 [error] <0.456.0>@ssl_config:file_error:366 Supervisor {<0.456.0>,ranch_acceptors_sup} had child {acceptor,<0.456.0>,4} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 4, {sslsocket,nil,{#Port<0.12>,{config,#{key => undefined,session_tickets => disabled,handshake => full,...},...}}}, ranch_ssl, logger) at <0.462.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:27:53.959 [error] <0.729.0>@ssl_config:file_error:366 CRASH REPORT Process <0.729.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 20:27:53.959 [error] <0.727.0>@ssl_config:file_error:366 Supervisor {<0.727.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.729.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:27:53.960 [error] <0.456.0>@ssl_config:file_error:366 Supervisor {<0.456.0>,ranch_acceptors_sup} had child {acceptor,<0.456.0>,5} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 5, {sslsocket,nil,{#Port<0.12>,{config,#{key => undefined,session_tickets => disabled,handshake => full,...},...}}}, ranch_ssl, logger) at <0.463.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:31:11.029 [error] <0.786.0>@ssl_config:file_error:366 CRASH REPORT Process <0.786.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 20:31:11.030 [error] <0.784.0>@ssl_config:file_error:366 Supervisor {<0.784.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.786.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:31:11.030 [error] <0.456.0>@ssl_config:file_error:366 Supervisor {<0.456.0>,ranch_acceptors_sup} had child {acceptor,<0.456.0>,6} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 6, {sslsocket,nil,{#Port<0.12>,{config,#{key => undefined,session_tickets => disabled,handshake => full,...},...}}}, ranch_ssl, logger) at <0.464.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:34:56.808 [error] <0.851.0>@ssl_config:file_error:366 CRASH REPORT Process <0.851.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 20:34:56.808 [error] <0.849.0>@ssl_config:file_error:366 Supervisor {<0.849.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.851.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:34:56.809 [error] <0.456.0>@ssl_config:file_error:366 Supervisor {<0.456.0>,ranch_acceptors_sup} had child {acceptor,<0.456.0>,7} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 7, {sslsocket,nil,{#Port<0.12>,{config,#{key => undefined,session_tickets => disabled,handshake => full,...},...}}}, ranch_ssl, logger) at <0.465.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:35:30.765 [error] <0.892.0>@ssl_config:file_error:366 CRASH REPORT Process <0.892.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 20:35:30.766 [error] <0.890.0>@ssl_config:file_error:366 Supervisor {<0.890.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.892.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:35:30.766 [error] <0.456.0>@ssl_config:file_error:366 Supervisor {<0.456.0>,ranch_acceptors_sup} had child {acceptor,<0.456.0>,8} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 8, {sslsocket,nil,{#Port<0.12>,{config,#{key => undefined,session_tickets => disabled,handshake => full,...},...}}}, ranch_ssl, logger) at <0.466.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:42:49.956 [info] <0.89.0> alarm_handler: {set,{system_memory_high_watermark,[]}}
2023-02-11 20:42:49.988 [info] <0.222.0>@vmq_swc_peer_service_manager:write_old_actor_to_disk:{180,13} writing (updated) old actor <<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>> to disk
2023-02-11 20:42:49.992 [info] <0.222.0>@vmq_swc_peer_service_manager:write_state_to_disk:{163,13} writing state {[{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}],{dict,1,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[['VerneMQ@127.0.0.1',{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}]],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}},{dict,0,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}}} to disk <<75,2,131,80,0,0,0,247,120,1,203,96,206,97,96,96,96,204,96,130,82,41,12,172,137,201,37,249,69,185,64,81,145,247,235,108,38,154,170,95,47,158,239,182,161,38,224,232,241,31,137,199,152,108,178,18,25,179,50,56,83,24,88,82,50,147,75,18,25,19,5,128,144,35,49,32,209,32,67,32,11,13,100,48,2,197,192,230,130,8,166,20,6,193,176,212,162,188,84,223,64,7,67,35,115,61,3,32,52,36,205,94,116,243,225,206,96,32,232,12,52,173,0,211,246,78,109>>
2023-02-11 20:42:50.073 [info] <0.228.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta1"
2023-02-11 20:42:50.083 [info] <0.238.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta2"
2023-02-11 20:42:50.088 [info] <0.247.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta3"
2023-02-11 20:42:50.092 [info] <0.256.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta4"
2023-02-11 20:42:50.097 [info] <0.265.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta5"
2023-02-11 20:42:50.101 [info] <0.274.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta6"
2023-02-11 20:42:50.107 [info] <0.283.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta7"
2023-02-11 20:42:50.112 [info] <0.292.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta8"
2023-02-11 20:42:50.116 [info] <0.301.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta9"
2023-02-11 20:42:50.121 [info] <0.310.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta10"
2023-02-11 20:42:50.143 [info] <0.215.0>@vmq_metadata:start:{29,5} Try to start vmq_swc: ok
2023-02-11 20:42:50.158 [info] <0.323.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/1"
2023-02-11 20:42:50.159 [info] <0.324.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/2"
2023-02-11 20:42:50.160 [info] <0.325.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/3"
2023-02-11 20:42:50.161 [info] <0.326.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/4"
2023-02-11 20:42:50.162 [info] <0.327.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/5"
2023-02-11 20:42:50.163 [info] <0.328.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/6"
2023-02-11 20:42:50.164 [info] <0.329.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/7"
2023-02-11 20:42:50.166 [info] <0.330.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/8"
2023-02-11 20:42:50.167 [info] <0.331.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/9"
2023-02-11 20:42:50.168 [info] <0.332.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/10"
2023-02-11 20:42:50.169 [info] <0.333.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/11"
2023-02-11 20:42:50.170 [info] <0.334.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/12"
2023-02-11 20:42:50.186 [info] <0.215.0>@vmq_message_store:start:{29,5} Try to start vmq_generic_msg_store: ok
2023-02-11 20:42:50.636 [info] <0.422.0>@vmq_reg_trie:handle_info:{254,5} loaded 0 subscriptions into vmq_reg_trie
2023-02-11 20:42:50.638 [info] <0.226.0>@vmq_cluster:init:{163,5} cluster event handler 'vmq_cluster' registered
2023-02-11 20:44:08.533 [error] <0.574.0>@ssl_config:file_error:366 CRASH REPORT Process <0.574.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 20:44:08.533 [error] <0.572.0>@ssl_config:file_error:366 Supervisor {<0.572.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.574.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:44:08.533 [error] <0.451.0>@ssl_config:file_error:366 Supervisor {<0.451.0>,ranch_acceptors_sup} had child {acceptor,<0.451.0>,1} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 1, {sslsocket,nil,{#Port<0.10>,{config,#{key => undefined,honor_ecc_order => false,secure_renegotiate => ...,...},...}}}, ranch_ssl, logger) at <0.454.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:53:26.619 [error] <0.614.0>@ssl_config:file_error:366 CRASH REPORT Process <0.614.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 20:53:26.619 [error] <0.451.0>@ssl_config:file_error:366 Supervisor {<0.451.0>,ranch_acceptors_sup} had child {acceptor,<0.451.0>,2} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 2, {sslsocket,nil,{#Port<0.10>,{config,#{key => undefined,honor_ecc_order => false,secure_renegotiate => ...,...},...}}}, ranch_ssl, logger) at <0.455.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:53:26.619 [error] <0.612.0>@ssl_config:file_error:366 Supervisor {<0.612.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.614.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:53:50.591 [error] <0.618.0>@vmq_cluster_com:process_bytes:171 CRASH REPORT Process <0.618.0> with 0 neighbours crashed with reason: bad argument in vmq_cluster_com:process_bytes/3 line 171
2023-02-11 20:54:27.855 [error] <0.626.0>@ssl_config:file_error:366 CRASH REPORT Process <0.626.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 20:54:27.855 [error] <0.624.0>@ssl_config:file_error:366 Supervisor {<0.624.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.626.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 20:54:27.855 [error] <0.451.0>@ssl_config:file_error:366 Supervisor {<0.451.0>,ranch_acceptors_sup} had child {acceptor,<0.451.0>,3} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 3, {sslsocket,nil,{#Port<0.10>,{config,#{key => undefined,honor_ecc_order => false,secure_renegotiate => ...,...},...}}}, ranch_ssl, logger) at <0.456.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 21:00:11.958 [error] <0.670.0>@ssl_config:file_error:366 CRASH REPORT Process <0.670.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 21:00:11.959 [error] <0.668.0>@ssl_config:file_error:366 Supervisor {<0.668.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.670.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 21:00:11.959 [error] <0.451.0>@ssl_config:file_error:366 Supervisor {<0.451.0>,ranch_acceptors_sup} had child {acceptor,<0.451.0>,4} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 4, {sslsocket,nil,{#Port<0.10>,{config,#{key => undefined,honor_ecc_order => false,secure_renegotiate => ...,...},...}}}, ranch_ssl, logger) at <0.457.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 21:07:57.662 [info] <0.734.0> Administrative stop
2023-02-11 21:07:57.781 [info] <0.89.0> alarm_handler: {clear,system_memory_high_watermark}
2023-02-11 21:08:04.702 [info] <0.89.0> alarm_handler: {set,{system_memory_high_watermark,[]}}
2023-02-11 21:08:04.761 [info] <0.222.0>@vmq_swc_peer_service_manager:write_old_actor_to_disk:{180,13} writing (updated) old actor <<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>> to disk
2023-02-11 21:08:04.765 [info] <0.222.0>@vmq_swc_peer_service_manager:write_state_to_disk:{163,13} writing state {[{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}],{dict,1,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[['VerneMQ@127.0.0.1',{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}]],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}},{dict,0,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}}} to disk <<75,2,131,80,0,0,0,247,120,1,203,96,206,97,96,96,96,204,96,130,82,41,12,172,137,201,37,249,69,185,64,81,145,247,235,108,38,154,170,95,47,158,239,182,161,38,224,232,241,31,137,199,152,108,178,18,25,179,50,56,83,24,88,82,50,147,75,18,25,19,5,128,144,35,49,32,209,32,67,32,11,13,100,48,2,197,192,230,130,8,166,20,6,193,176,212,162,188,84,223,64,7,67,35,115,61,3,32,52,36,205,94,116,243,225,206,96,32,232,12,52,173,0,211,246,78,109>>
2023-02-11 21:08:04.787 [info] <0.228.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta1"
2023-02-11 21:08:04.795 [info] <0.238.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta2"
2023-02-11 21:08:04.797 [info] <0.247.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta3"
2023-02-11 21:08:04.798 [info] <0.256.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta4"
2023-02-11 21:08:04.813 [info] <0.265.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta5"
2023-02-11 21:08:04.816 [info] <0.274.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta6"
2023-02-11 21:08:04.831 [info] <0.283.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta7"
2023-02-11 21:08:04.838 [info] <0.292.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta8"
2023-02-11 21:08:04.842 [info] <0.301.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta9"
2023-02-11 21:08:04.845 [info] <0.310.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta10"
2023-02-11 21:08:04.874 [info] <0.215.0>@vmq_metadata:start:{29,5} Try to start vmq_swc: ok
2023-02-11 21:08:04.889 [info] <0.323.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/1"
2023-02-11 21:08:04.891 [info] <0.324.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/2"
2023-02-11 21:08:04.892 [info] <0.325.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/3"
2023-02-11 21:08:04.894 [info] <0.326.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/4"
2023-02-11 21:08:04.895 [info] <0.327.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/5"
2023-02-11 21:08:04.897 [info] <0.328.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/6"
2023-02-11 21:08:04.898 [info] <0.329.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/7"
2023-02-11 21:08:04.900 [info] <0.330.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/8"
2023-02-11 21:08:04.901 [info] <0.331.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/9"
2023-02-11 21:08:04.903 [info] <0.332.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/10"
2023-02-11 21:08:04.904 [info] <0.333.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/11"
2023-02-11 21:08:04.905 [info] <0.334.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/12"
2023-02-11 21:08:04.933 [info] <0.215.0>@vmq_message_store:start:{29,5} Try to start vmq_generic_msg_store: ok
2023-02-11 21:08:05.152 [info] <0.422.0>@vmq_reg_trie:handle_info:{254,5} loaded 0 subscriptions into vmq_reg_trie
2023-02-11 21:08:05.157 [info] <0.226.0>@vmq_cluster:init:{163,5} cluster event handler 'vmq_cluster' registered
2023-02-11 21:08:52.438 [error] <0.575.0>@ssl_config:file_error:366 CRASH REPORT Process <0.575.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 21:08:52.438 [error] <0.573.0>@ssl_config:file_error:366 Supervisor {<0.573.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.575.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 21:08:52.438 [error] <0.451.0>@ssl_config:file_error:366 Supervisor {<0.451.0>,ranch_acceptors_sup} had child {acceptor,<0.451.0>,1} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 1, {sslsocket,nil,{#Port<0.10>,{config,#{key => undefined,honor_ecc_order => false,secure_renegotiate => ...,...},...}}}, ranch_ssl, logger) at <0.454.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 21:20:30.612 [error] <0.589.0>@ssl_config:file_error:366 CRASH REPORT Process <0.589.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 21:20:30.612 [error] <0.451.0>@ssl_config:file_error:366 Supervisor {<0.451.0>,ranch_acceptors_sup} had child {acceptor,<0.451.0>,2} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 2, {sslsocket,nil,{#Port<0.10>,{config,#{key => undefined,honor_ecc_order => false,secure_renegotiate => ...,...},...}}}, ranch_ssl, logger) at <0.455.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 21:20:30.612 [error] <0.587.0>@ssl_config:file_error:366 Supervisor {<0.587.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.589.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 21:56:57.700 [error] <0.612.0>@ssl_config:file_error:366 CRASH REPORT Process <0.612.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 21:56:57.700 [error] <0.610.0>@ssl_config:file_error:366 Supervisor {<0.610.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.612.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 21:56:57.700 [error] <0.451.0>@ssl_config:file_error:366 Supervisor {<0.451.0>,ranch_acceptors_sup} had child {acceptor,<0.451.0>,3} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 3, {sslsocket,nil,{#Port<0.10>,{config,#{key => undefined,honor_ecc_order => false,secure_renegotiate => ...,...},...}}}, ranch_ssl, logger) at <0.456.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 21:59:26.523 [info] <0.620.0> Administrative stop
2023-02-11 21:59:26.535 [info] <0.89.0> alarm_handler: {clear,system_memory_high_watermark}
2023-02-11 21:59:35.312 [info] <0.89.0> alarm_handler: {set,{system_memory_high_watermark,[]}}
2023-02-11 21:59:35.370 [info] <0.222.0>@vmq_swc_peer_service_manager:write_old_actor_to_disk:{180,13} writing (updated) old actor <<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>> to disk
2023-02-11 21:59:35.373 [info] <0.222.0>@vmq_swc_peer_service_manager:write_state_to_disk:{163,13} writing state {[{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}],{dict,1,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[['VerneMQ@127.0.0.1',{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}]],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}},{dict,0,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}}} to disk <<75,2,131,80,0,0,0,247,120,1,203,96,206,97,96,96,96,204,96,130,82,41,12,172,137,201,37,249,69,185,64,81,145,247,235,108,38,154,170,95,47,158,239,182,161,38,224,232,241,31,137,199,152,108,178,18,25,179,50,56,83,24,88,82,50,147,75,18,25,19,5,128,144,35,49,32,209,32,67,32,11,13,100,48,2,197,192,230,130,8,166,20,6,193,176,212,162,188,84,223,64,7,67,35,115,61,3,32,52,36,205,94,116,243,225,206,96,32,232,12,52,173,0,211,246,78,109>>
2023-02-11 21:59:35.394 [info] <0.228.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta1"
2023-02-11 21:59:35.402 [info] <0.238.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta2"
2023-02-11 21:59:35.404 [info] <0.247.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta3"
2023-02-11 21:59:35.406 [info] <0.256.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta4"
2023-02-11 21:59:35.418 [info] <0.265.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta5"
2023-02-11 21:59:35.450 [info] <0.274.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta6"
2023-02-11 21:59:35.471 [info] <0.283.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta7"
2023-02-11 21:59:35.476 [info] <0.292.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta8"
2023-02-11 21:59:35.495 [info] <0.301.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta9"
2023-02-11 21:59:35.513 [info] <0.310.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta10"
2023-02-11 21:59:35.538 [info] <0.215.0>@vmq_metadata:start:{29,5} Try to start vmq_swc: ok
2023-02-11 21:59:35.553 [info] <0.323.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/1"
2023-02-11 21:59:35.554 [info] <0.324.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/2"
2023-02-11 21:59:35.556 [info] <0.325.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/3"
2023-02-11 21:59:35.558 [info] <0.326.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/4"
2023-02-11 21:59:35.559 [info] <0.327.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/5"
2023-02-11 21:59:35.560 [info] <0.328.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/6"
2023-02-11 21:59:35.562 [info] <0.329.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/7"
2023-02-11 21:59:35.563 [info] <0.330.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/8"
2023-02-11 21:59:35.564 [info] <0.331.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/9"
2023-02-11 21:59:35.565 [info] <0.332.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/10"
2023-02-11 21:59:35.567 [info] <0.333.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/11"
2023-02-11 21:59:35.568 [info] <0.334.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/12"
2023-02-11 21:59:35.596 [info] <0.215.0>@vmq_message_store:start:{29,5} Try to start vmq_generic_msg_store: ok
2023-02-11 21:59:36.452 [info] <0.424.0>@vmq_reg_trie:handle_info:{254,5} loaded 0 subscriptions into vmq_reg_trie
2023-02-11 21:59:36.456 [info] <0.226.0>@vmq_cluster:init:{163,5} cluster event handler 'vmq_cluster' registered
2023-02-11 22:00:20.259 [error] <0.575.0>@ssl_config:file_error:366 CRASH REPORT Process <0.575.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 22:00:20.259 [error] <0.573.0>@ssl_config:file_error:366 Supervisor {<0.573.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.575.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 22:00:20.260 [error] <0.453.0>@ssl_config:file_error:366 Supervisor {<0.453.0>,ranch_acceptors_sup} had child {acceptor,<0.453.0>,1} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 1, {sslsocket,nil,{#Port<0.11>,{config,#{key => undefined,use_ticket => undefined,handshake => full,...},...}}}, ranch_ssl, logger) at <0.456.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 22:07:11.026 [error] <0.582.0>@ssl_config:file_error:366 CRASH REPORT Process <0.582.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 22:07:11.026 [error] <0.580.0>@ssl_config:file_error:366 Supervisor {<0.580.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.582.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 22:07:11.026 [error] <0.453.0>@ssl_config:file_error:366 Supervisor {<0.453.0>,ranch_acceptors_sup} had child {acceptor,<0.453.0>,2} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 2, {sslsocket,nil,{#Port<0.11>,{config,#{key => undefined,use_ticket => undefined,handshake => full,...},...}}}, ranch_ssl, logger) at <0.457.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 22:17:17.944 [info] <0.595.0> Administrative stop
2023-02-11 22:17:17.953 [info] <0.89.0> alarm_handler: {clear,system_memory_high_watermark}
2023-02-11 22:17:28.293 [info] <0.89.0> alarm_handler: {set,{system_memory_high_watermark,[]}}
2023-02-11 22:17:28.353 [info] <0.222.0>@vmq_swc_peer_service_manager:write_old_actor_to_disk:{180,13} writing (updated) old actor <<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>> to disk
2023-02-11 22:17:28.356 [info] <0.222.0>@vmq_swc_peer_service_manager:write_state_to_disk:{163,13} writing state {[{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}],{dict,1,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[['VerneMQ@127.0.0.1',{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}]],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}},{dict,0,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}}} to disk <<75,2,131,80,0,0,0,247,120,1,203,96,206,97,96,96,96,204,96,130,82,41,12,172,137,201,37,249,69,185,64,81,145,247,235,108,38,154,170,95,47,158,239,182,161,38,224,232,241,31,137,199,152,108,178,18,25,179,50,56,83,24,88,82,50,147,75,18,25,19,5,128,144,35,49,32,209,32,67,32,11,13,100,48,2,197,192,230,130,8,166,20,6,193,176,212,162,188,84,223,64,7,67,35,115,61,3,32,52,36,205,94,116,243,225,206,96,32,232,12,52,173,0,211,246,78,109>>
2023-02-11 22:17:28.374 [info] <0.228.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta1"
2023-02-11 22:17:28.380 [info] <0.238.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta2"
2023-02-11 22:17:28.382 [info] <0.247.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta3"
2023-02-11 22:17:28.383 [info] <0.256.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta4"
2023-02-11 22:17:28.385 [info] <0.265.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta5"
2023-02-11 22:17:28.387 [info] <0.274.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta6"
2023-02-11 22:17:28.389 [info] <0.283.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta7"
2023-02-11 22:17:28.391 [info] <0.292.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta8"
2023-02-11 22:17:28.393 [info] <0.301.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta9"
2023-02-11 22:17:28.395 [info] <0.310.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta10"
2023-02-11 22:17:28.415 [info] <0.215.0>@vmq_metadata:start:{29,5} Try to start vmq_swc: ok
2023-02-11 22:17:28.429 [info] <0.323.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/1"
2023-02-11 22:17:28.439 [info] <0.324.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/2"
2023-02-11 22:17:28.440 [info] <0.325.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/3"
2023-02-11 22:17:28.441 [info] <0.326.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/4"
2023-02-11 22:17:28.442 [info] <0.327.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/5"
2023-02-11 22:17:28.443 [info] <0.328.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/6"
2023-02-11 22:17:28.444 [info] <0.329.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/7"
2023-02-11 22:17:28.445 [info] <0.330.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/8"
2023-02-11 22:17:28.447 [info] <0.331.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/9"
2023-02-11 22:17:28.448 [info] <0.332.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/10"
2023-02-11 22:17:28.449 [info] <0.333.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/11"
2023-02-11 22:17:28.450 [info] <0.334.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/12"
2023-02-11 22:17:28.465 [info] <0.215.0>@vmq_message_store:start:{29,5} Try to start vmq_generic_msg_store: ok
2023-02-11 22:17:28.957 [info] <0.424.0>@vmq_reg_trie:handle_info:{254,5} loaded 0 subscriptions into vmq_reg_trie
2023-02-11 22:17:28.960 [info] <0.226.0>@vmq_cluster:init:{163,5} cluster event handler 'vmq_cluster' registered
2023-02-11 22:17:28.974 [error] <0.440.0>@vmq_ranch_config:reconfigure_listeners_for_type:{269,13} can't reconfigure mqtts listener({127,0,0,1}, 1883) with Options [{max_connections,10000},{nr_of_acceptors,10},{mountpoint,[]},{depth,1},{eccs,[sect571r1,sect571k1,secp521r1,brainpoolP512r1,sect409k1,sect409r1,brainpoolP384r1,secp384r1,sect283k1,sect283r1,brainpoolP256r1,secp256k1,secp256r1,sect239k1,sect233k1,sect233r1,secp224k1,secp224r1,sect193r1,sect193r2,secp192k1,secp192r1,sect163k1,sect163r1,sect163r2,secp160k1,secp160r1,secp160r2]},{require_certificate,false},{tls_version,'tlsv1.2'},{use_identity_as_username,false},{allowed_protocol_versions,[3,4,131]},{allow_anonymous_override,true}] due to {already_started,<0.441.0>}
2023-02-11 22:17:28.981 [error] <0.440.0>@vmq_ranch_config:reconfigure_listeners_for_type:{269,13} can't reconfigure http listener({127,0,0,1}, 8888) with Options [{max_connections,10000},{nr_of_acceptors,10},{config_mod,vmq_http_config},{config_fun,config},{proxy_protocol,false}] due to {already_started,<0.464.0>}
2023-02-11 22:19:25.460 [warning] <0.582.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to '{cant_parse_connect_fixed_header,<<"GET /status HTTP/1.1\r\nHost: localhost:1883\r\nConnection: keep-alive\r\nsec-ch-ua: \"Not_A Brand\";v=\"99\", \"Google Chrome\";v=\"109\", \"Chromium\";v=\"109\"\r\nsec-ch-ua-mobile: ?0\r\nsec-ch-ua-platform: \"macOS\"\r\nUpgrade-Insecure-Requests: 1\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\r\nSec-Fetch-Site: none\r\nSec-Fetch-Mode: navigate\r\nSec-Fetch-User: ?1\r\nSec-Fetch-Dest: document\r\nAccept-Encoding: gzip, deflate, br\r\nAccept-Language: en-GB,en-US;q=0.9,en;q=0.8\r\n\r\n">>}'
2023-02-11 22:19:26.489 [warning] <0.583.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to '{cant_parse_connect_fixed_header,<<"GET /status HTTP/1.1\r\nHost: localhost:1883\r\nConnection: keep-alive\r\nCache-Control: max-age=0\r\nsec-ch-ua: \"Not_A Brand\";v=\"99\", \"Google Chrome\";v=\"109\", \"Chromium\";v=\"109\"\r\nsec-ch-ua-mobile: ?0\r\nsec-ch-ua-platform: \"macOS\"\r\nUpgrade-Insecure-Requests: 1\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\r\nSec-Fetch-Site: none\r\nSec-Fetch-Mode: navigate\r\nSec-Fetch-User: ?1\r\nSec-Fetch-Dest: document\r\nAccept-Encoding: gzip, deflate, br\r\nAccept-Language: en-GB,en-US;q=0.9,en;q=0.8\r\n\r\n">>}'
2023-02-11 22:19:26.490 [warning] <0.584.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to '{cant_parse_connect_fixed_header,<<"GET /status HTTP/1.1\r\nHost: localhost:1883\r\nConnection: keep-alive\r\nCache-Control: max-age=0\r\nsec-ch-ua: \"Not_A Brand\";v=\"99\", \"Google Chrome\";v=\"109\", \"Chromium\";v=\"109\"\r\nsec-ch-ua-mobile: ?0\r\nsec-ch-ua-platform: \"macOS\"\r\nUpgrade-Insecure-Requests: 1\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\r\nSec-Fetch-Site: none\r\nSec-Fetch-Mode: navigate\r\nSec-Fetch-User: ?1\r\nSec-Fetch-Dest: document\r\nAccept-Encoding: gzip, deflate, br\r\nAccept-Language: en-GB,en-US;q=0.9,en;q=0.8\r\n\r\n">>}'
2023-02-11 22:19:26.491 [warning] <0.585.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to '{cant_parse_connect_fixed_header,<<"GET /status HTTP/1.1\r\nHost: localhost:1883\r\nConnection: keep-alive\r\nCache-Control: max-age=0\r\nsec-ch-ua: \"Not_A Brand\";v=\"99\", \"Google Chrome\";v=\"109\", \"Chromium\";v=\"109\"\r\nsec-ch-ua-mobile: ?0\r\nsec-ch-ua-platform: \"macOS\"\r\nUpgrade-Insecure-Requests: 1\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\r\nSec-Fetch-Site: none\r\nSec-Fetch-Mode: navigate\r\nSec-Fetch-User: ?1\r\nSec-Fetch-Dest: document\r\nAccept-Encoding: gzip, deflate, br\r\nAccept-Language: en-GB,en-US;q=0.9,en;q=0.8\r\n\r\n">>}'
2023-02-11 22:19:27.577 [warning] <0.586.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to '{cant_parse_connect_fixed_header,<<"GET /status HTTP/1.1\r\nHost: localhost:1883\r\nConnection: keep-alive\r\nCache-Control: max-age=0\r\nsec-ch-ua: \"Not_A Brand\";v=\"99\", \"Google Chrome\";v=\"109\", \"Chromium\";v=\"109\"\r\nsec-ch-ua-mobile: ?0\r\nsec-ch-ua-platform: \"macOS\"\r\nUpgrade-Insecure-Requests: 1\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\r\nSec-Fetch-Site: cross-site\r\nSec-Fetch-Mode: navigate\r\nSec-Fetch-User: ?1\r\nSec-Fetch-Dest: document\r\nAccept-Encoding: gzip, deflate, br\r\nAccept-Language: en-GB,en-US;q=0.9,en;q=0.8\r\n\r\n">>}'
2023-02-11 22:20:56.412 [info] <0.614.0> Administrative stop
2023-02-11 22:20:56.420 [info] <0.89.0> alarm_handler: {clear,system_memory_high_watermark}
2023-02-11 22:22:21.530 [info] <0.89.0> alarm_handler: {set,{system_memory_high_watermark,[]}}
2023-02-11 22:22:21.574 [info] <0.222.0>@vmq_swc_peer_service_manager:write_old_actor_to_disk:{180,13} writing (updated) old actor <<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>> to disk
2023-02-11 22:22:21.578 [info] <0.222.0>@vmq_swc_peer_service_manager:write_state_to_disk:{163,13} writing state {[{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}],{dict,1,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[['VerneMQ@127.0.0.1',{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}]],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}},{dict,0,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}}} to disk <<75,2,131,80,0,0,0,247,120,1,203,96,206,97,96,96,96,204,96,130,82,41,12,172,137,201,37,249,69,185,64,81,145,247,235,108,38,154,170,95,47,158,239,182,161,38,224,232,241,31,137,199,152,108,178,18,25,179,50,56,83,24,88,82,50,147,75,18,25,19,5,128,144,35,49,32,209,32,67,32,11,13,100,48,2,197,192,230,130,8,166,20,6,193,176,212,162,188,84,223,64,7,67,35,115,61,3,32,52,36,205,94,116,243,225,206,96,32,232,12,52,173,0,211,246,78,109>>
2023-02-11 22:22:21.631 [info] <0.228.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta1"
2023-02-11 22:22:21.640 [info] <0.240.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta2"
2023-02-11 22:22:21.642 [info] <0.249.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta3"
2023-02-11 22:22:21.644 [info] <0.258.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta4"
2023-02-11 22:22:21.646 [info] <0.267.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta5"
2023-02-11 22:22:21.648 [info] <0.276.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta6"
2023-02-11 22:22:21.650 [info] <0.285.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta7"
2023-02-11 22:22:21.652 [info] <0.294.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta8"
2023-02-11 22:22:21.654 [info] <0.303.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta9"
2023-02-11 22:22:21.656 [info] <0.312.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta10"
2023-02-11 22:22:21.679 [info] <0.215.0>@vmq_metadata:start:{29,5} Try to start vmq_swc: ok
2023-02-11 22:22:21.695 [info] <0.325.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/1"
2023-02-11 22:22:21.696 [info] <0.326.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/2"
2023-02-11 22:22:21.697 [info] <0.327.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/3"
2023-02-11 22:22:21.698 [info] <0.328.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/4"
2023-02-11 22:22:21.699 [info] <0.329.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/5"
2023-02-11 22:22:21.700 [info] <0.330.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/6"
2023-02-11 22:22:21.702 [info] <0.331.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/7"
2023-02-11 22:22:21.703 [info] <0.332.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/8"
2023-02-11 22:22:21.704 [info] <0.333.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/9"
2023-02-11 22:22:21.705 [info] <0.334.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/10"
2023-02-11 22:22:21.707 [info] <0.335.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/11"
2023-02-11 22:22:21.709 [info] <0.336.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/12"
2023-02-11 22:22:22.296 [info] <0.215.0>@vmq_message_store:start:{29,5} Try to start vmq_generic_msg_store: ok
2023-02-11 22:22:22.356 [info] <0.427.0>@vmq_reg_trie:handle_info:{254,5} loaded 0 subscriptions into vmq_reg_trie
2023-02-11 22:22:22.359 [info] <0.226.0>@vmq_cluster:init:{163,5} cluster event handler 'vmq_cluster' registered
2023-02-11 22:22:22.381 [error] <0.443.0>@vmq_ranch_config:reconfigure_listeners_for_type:{269,13} can't reconfigure mqttws listener({127,0,0,1}, 8888) with Options [{max_connections,10000},{nr_of_acceptors,10},{mountpoint,[]},{proxy_protocol,false},{allowed_protocol_versions,[3,4,131]}] due to {already_started,<0.444.0>}
2023-02-11 22:22:22.385 [error] <0.443.0>@vmq_ranch_config:reconfigure_listeners_for_type:{269,13} can't reconfigure http listener({127,0,0,1}, 8888) with Options [{max_connections,10000},{nr_of_acceptors,10},{config_mod,vmq_http_config},{config_fun,config},{proxy_protocol,false}] due to {already_started,<0.444.0>}
2023-02-11 22:22:56.276 [warning] <0.578.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to '{cant_parse_connect_fixed_header,<<"GET /status HTTP/1.1\r\nHost: localhost:8888\r\nUpgrade-Insecure-Requests: 1\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15\r\nAccept-Language: en-IN,en-GB;q=0.9,en;q=0.8\r\nAccept-Encoding: gzip, deflate\r\nConnection: keep-alive\r\n\r\n">>}'
2023-02-11 22:22:56.284 [warning] <0.577.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to '{cant_parse_connect_fixed_header,<<"GET /status HTTP/1.1\r\nHost: localhost:8888\r\nUpgrade-Insecure-Requests: 1\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15\r\nAccept-Language: en-IN,en-GB;q=0.9,en;q=0.8\r\nAccept-Encoding: gzip, deflate\r\nConnection: keep-alive\r\n\r\n">>}'
2023-02-11 22:22:56.342 [warning] <0.579.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to '{cant_parse_connect_fixed_header,<<"GET /status HTTP/1.1\r\nHost: localhost:8888\r\nUpgrade-Insecure-Requests: 1\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15\r\nAccept-Language: en-IN,en-GB;q=0.9,en;q=0.8\r\nAccept-Encoding: gzip, deflate\r\nConnection: keep-alive\r\n\r\n">>}'
2023-02-11 22:23:05.963 [error] <0.585.0>@ssl_config:file_error:366 CRASH REPORT Process <0.585.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 22:23:05.963 [error] <0.582.0>@ssl_config:file_error:366 CRASH REPORT Process <0.582.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 22:23:05.963 [error] <0.583.0>@ssl_config:file_error:366 Supervisor {<0.583.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.585.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 22:23:05.963 [error] <0.479.0>@ssl_config:file_error:366 Supervisor {<0.479.0>,ranch_acceptors_sup} had child {acceptor,<0.479.0>,2} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 2, {sslsocket,nil,{#Port<0.13>,{config,#{key => undefined,handshake => full,crl_cache => {ssl_crl_cache,...},...},...}}}, ranch_ssl, logger) at <0.483.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 22:23:05.963 [error] <0.580.0>@ssl_config:file_error:366 Supervisor {<0.580.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.582.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 22:23:05.964 [error] <0.479.0>@ssl_config:file_error:366 Supervisor {<0.479.0>,ranch_acceptors_sup} had child {acceptor,<0.479.0>,1} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 1, {sslsocket,nil,{#Port<0.13>,{config,#{key => undefined,handshake => full,crl_cache => {ssl_crl_cache,...},...},...}}}, ranch_ssl, logger) at <0.482.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 22:23:06.018 [error] <0.590.0>@ssl_config:file_error:366 CRASH REPORT Process <0.590.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 22:23:06.018 [error] <0.588.0>@ssl_config:file_error:366 Supervisor {<0.588.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.590.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 22:23:06.019 [error] <0.479.0>@ssl_config:file_error:366 Supervisor {<0.479.0>,ranch_acceptors_sup} had child {acceptor,<0.479.0>,3} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 3, {sslsocket,nil,{#Port<0.13>,{config,#{key => undefined,handshake => full,crl_cache => {ssl_crl_cache,...},...},...}}}, ranch_ssl, logger) at <0.484.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 22:23:33.187 [warning] <0.592.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to '{cant_parse_connect_fixed_header,<<"GET /status HTTP/1.1\r\nHost: localhost:8888\r\nUpgrade-Insecure-Requests: 1\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15\r\nAccept-Language: en-IN,en-GB;q=0.9,en;q=0.8\r\nAccept-Encoding: gzip, deflate\r\nConnection: keep-alive\r\n\r\n">>}'
2023-02-11 22:23:33.245 [warning] <0.594.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to '{cant_parse_connect_fixed_header,<<"GET /status HTTP/1.1\r\nHost: localhost:8888\r\nUpgrade-Insecure-Requests: 1\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15\r\nAccept-Language: en-IN,en-GB;q=0.9,en;q=0.8\r\nAccept-Encoding: gzip, deflate\r\nConnection: keep-alive\r\n\r\n">>}'
2023-02-11 22:23:33.246 [warning] <0.593.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to '{cant_parse_connect_fixed_header,<<"GET /status HTTP/1.1\r\nHost: localhost:8888\r\nUpgrade-Insecure-Requests: 1\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15\r\nAccept-Language: en-IN,en-GB;q=0.9,en;q=0.8\r\nAccept-Encoding: gzip, deflate\r\nConnection: keep-alive\r\n\r\n">>}'
2023-02-11 22:23:35.418 [warning] <0.595.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to '{cant_parse_connect_fixed_header,<<"GET /status HTTP/1.1\r\nHost: localhost:8888\r\nUpgrade-Insecure-Requests: 1\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15\r\nAccept-Language: en-IN,en-GB;q=0.9,en;q=0.8\r\nAccept-Encoding: gzip, deflate\r\nConnection: keep-alive\r\n\r\n">>}'
2023-02-11 22:23:35.476 [warning] <0.597.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to '{cant_parse_connect_fixed_header,<<"GET /status HTTP/1.1\r\nHost: localhost:8888\r\nUpgrade-Insecure-Requests: 1\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15\r\nAccept-Language: en-IN,en-GB;q=0.9,en;q=0.8\r\nAccept-Encoding: gzip, deflate\r\nConnection: keep-alive\r\n\r\n">>}'
2023-02-11 22:23:35.477 [warning] <0.596.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to '{cant_parse_connect_fixed_header,<<"GET /status HTTP/1.1\r\nHost: localhost:8888\r\nUpgrade-Insecure-Requests: 1\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\r\nUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15\r\nAccept-Language: en-IN,en-GB;q=0.9,en;q=0.8\r\nAccept-Encoding: gzip, deflate\r\nConnection: keep-alive\r\n\r\n">>}'
2023-02-11 22:24:58.414 [error] <0.603.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-SpJxREhZXaAyRxQ3naX760h58Cc=">>},0,[<<"test">>],<<"message">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:25:16.199 [error] <0.603.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-SpJxREhZXaAyRxQ3naX760h58Cc=">>},0,[<<"test">>],<<"message">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:25:17.005 [error] <0.603.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-SpJxREhZXaAyRxQ3naX760h58Cc=">>},0,[<<"test">>],<<"message">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:25:17.738 [error] <0.603.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-SpJxREhZXaAyRxQ3naX760h58Cc=">>},0,[<<"test">>],<<"message">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:25:18.525 [error] <0.603.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-SpJxREhZXaAyRxQ3naX760h58Cc=">>},0,[<<"test">>],<<"message">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:25:19.310 [error] <0.603.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-SpJxREhZXaAyRxQ3naX760h58Cc=">>},0,[<<"test">>],<<"message">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:25:20.038 [error] <0.603.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-SpJxREhZXaAyRxQ3naX760h58Cc=">>},0,[<<"test">>],<<"message">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:25:20.740 [error] <0.603.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-SpJxREhZXaAyRxQ3naX760h58Cc=">>},0,[<<"test">>],<<"message">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:25:21.465 [error] <0.603.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-SpJxREhZXaAyRxQ3naX760h58Cc=">>},0,[<<"test">>],<<"message">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:25:22.217 [error] <0.603.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-SpJxREhZXaAyRxQ3naX760h58Cc=">>},0,[<<"test">>],<<"message">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:25:22.908 [error] <0.603.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-SpJxREhZXaAyRxQ3naX760h58Cc=">>},0,[<<"test">>],<<"message">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:26:14.781 [error] <0.609.0>@ssl_config:file_error:366 CRASH REPORT Process <0.609.0> with 0 neighbours crashed with reason: bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366
2023-02-11 22:26:14.781 [error] <0.607.0>@ssl_config:file_error:366 Supervisor {<0.607.0>,tls_dyn_connection_sup} had child receiver started with {ssl_gen_statem,start_link,undefined} at <0.609.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 22:26:14.781 [error] <0.479.0>@ssl_config:file_error:366 Supervisor {<0.479.0>,ranch_acceptors_sup} had child {acceptor,<0.479.0>,4} started with ranch_acceptor:start_link({{127,0,0,1},1883}, 4, {sslsocket,nil,{#Port<0.13>,{config,#{key => undefined,handshake => full,crl_cache => {ssl_crl_cache,...},...},...}}}, ranch_ssl, logger) at <0.485.0> exit with reason bad argument in call to erlang:binary_to_list(undefined) in ssl_config:file_error/2 line 366 in context child_terminated
2023-02-11 22:28:15.683 [info] <0.617.0> Administrative stop
2023-02-11 22:28:15.692 [info] <0.89.0> alarm_handler: {clear,system_memory_high_watermark}
2023-02-11 22:28:33.182 [info] <0.89.0> alarm_handler: {set,{system_memory_high_watermark,[]}}
2023-02-11 22:28:33.242 [info] <0.222.0>@vmq_swc_peer_service_manager:write_old_actor_to_disk:{180,13} writing (updated) old actor <<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>> to disk
2023-02-11 22:28:33.245 [info] <0.222.0>@vmq_swc_peer_service_manager:write_state_to_disk:{163,13} writing state {[{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}],{dict,1,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[['VerneMQ@127.0.0.1',{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}]],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}},{dict,0,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}}} to disk <<75,2,131,80,0,0,0,247,120,1,203,96,206,97,96,96,96,204,96,130,82,41,12,172,137,201,37,249,69,185,64,81,145,247,235,108,38,154,170,95,47,158,239,182,161,38,224,232,241,31,137,199,152,108,178,18,25,179,50,56,83,24,88,82,50,147,75,18,25,19,5,128,144,35,49,32,209,32,67,32,11,13,100,48,2,197,192,230,130,8,166,20,6,193,176,212,162,188,84,223,64,7,67,35,115,61,3,32,52,36,205,94,116,243,225,206,96,32,232,12,52,173,0,211,246,78,109>>
2023-02-11 22:28:33.264 [info] <0.228.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta1"
2023-02-11 22:28:33.273 [info] <0.238.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta2"
2023-02-11 22:28:33.275 [info] <0.247.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta3"
2023-02-11 22:28:33.280 [info] <0.256.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta4"
2023-02-11 22:28:33.297 [info] <0.265.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta5"
2023-02-11 22:28:33.310 [info] <0.274.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta6"
2023-02-11 22:28:33.325 [info] <0.283.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta7"
2023-02-11 22:28:33.329 [info] <0.292.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta8"
2023-02-11 22:28:33.341 [info] <0.301.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta9"
2023-02-11 22:28:33.343 [info] <0.310.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta10"
2023-02-11 22:28:33.377 [info] <0.215.0>@vmq_metadata:start:{29,5} Try to start vmq_swc: ok
2023-02-11 22:28:33.392 [info] <0.323.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/1"
2023-02-11 22:28:33.393 [info] <0.324.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/2"
2023-02-11 22:28:33.394 [info] <0.325.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/3"
2023-02-11 22:28:33.396 [info] <0.326.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/4"
2023-02-11 22:28:33.397 [info] <0.327.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/5"
2023-02-11 22:28:33.398 [info] <0.328.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/6"
2023-02-11 22:28:33.400 [info] <0.329.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/7"
2023-02-11 22:28:33.401 [info] <0.330.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/8"
2023-02-11 22:28:33.402 [info] <0.331.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/9"
2023-02-11 22:28:33.404 [info] <0.332.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/10"
2023-02-11 22:28:33.405 [info] <0.333.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/11"
2023-02-11 22:28:33.407 [info] <0.334.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/12"
2023-02-11 22:28:33.425 [info] <0.215.0>@vmq_message_store:start:{29,5} Try to start vmq_generic_msg_store: ok
2023-02-11 22:28:33.664 [info] <0.422.0>@vmq_reg_trie:handle_info:{254,5} loaded 0 subscriptions into vmq_reg_trie
2023-02-11 22:28:33.667 [info] <0.226.0>@vmq_cluster:init:{163,5} cluster event handler 'vmq_cluster' registered
2023-02-11 22:28:33.683 [error] <0.438.0>@vmq_ranch_config:reconfigure_listeners_for_type:{269,13} can't reconfigure mqtts listener({127,0,0,1}, 1883) with Options [{max_connections,10000},{nr_of_acceptors,10},{mountpoint,[]},{depth,1},{eccs,[sect571r1,sect571k1,secp521r1,brainpoolP512r1,sect409k1,sect409r1,brainpoolP384r1,secp384r1,sect283k1,sect283r1,brainpoolP256r1,secp256k1,secp256r1,sect239k1,sect233k1,sect233r1,secp224k1,secp224r1,sect193r1,sect193r2,secp192k1,secp192r1,sect163k1,sect163r1,sect163r2,secp160k1,secp160r1,secp160r2]},{require_certificate,false},{tls_version,'tlsv1.2'},{use_identity_as_username,false},{allowed_protocol_versions,[3,4,131]},{allow_anonymous_override,false}] due to {already_started,<0.439.0>}
2023-02-11 22:29:46.780 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"random_topic">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:29:48.660 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"random_topic">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:29:49.685 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"random_topic">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:29:51.256 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"random_topic">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:29:52.317 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"random_topic">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:35:53.641 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"random_topic">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:35:54.693 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"random_topic">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:35:55.434 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"random_topic">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:35:56.155 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"random_topic">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:35:56.844 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"random_topic">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:38:38.182 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"test">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:38:40.953 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"test">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:54:43.872 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"test">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:54:44.599 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"test">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:54:45.508 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"test">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:54:48.270 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"random_topic">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 22:54:50.186 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"random_topic">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 23:14:20.989 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"random_topic">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 23:22:24.001 [warning] <0.773.0>@vmq_mqtt5_fsm:connected:{819,13} client {[],<<"mqttx_c43c6422">>} with username <<>> stopped due to keepalive expired
2023-02-11 23:22:24.001 [warning] <0.773.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to 'keep_alive_timeout'
2023-02-11 23:25:05.257 [error] <0.574.0>@vmq_mqtt5_fsm:auth_on_publish:{1525,13} can't auth publish [undefined,{[],<<"anon-7NHKCw/QzObxkawMtKnWXGhvAfc=">>},0,[<<"test">>],<<"Hello World">>,false,#{}] due to no_matching_hook_found
2023-02-11 23:29:34.948 [info] <0.1019.0> Administrative stop
2023-02-11 23:29:34.963 [info] <0.89.0> alarm_handler: {clear,system_memory_high_watermark}
2023-02-11 23:29:42.735 [info] <0.89.0> alarm_handler: {set,{system_memory_high_watermark,[]}}
2023-02-11 23:29:42.795 [info] <0.222.0>@vmq_swc_peer_service_manager:write_old_actor_to_disk:{180,13} writing (updated) old actor <<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>> to disk
2023-02-11 23:29:42.798 [info] <0.222.0>@vmq_swc_peer_service_manager:write_state_to_disk:{163,13} writing state {[{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}],{dict,1,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[['VerneMQ@127.0.0.1',{[{actor,<<239,174,60,145,53,39,215,115,159,70,176,124,80,197,199,248,97,198,2,60>>}],1}]],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}},{dict,0,16,16,8,80,48,{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]},{{[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[]}}}} to disk <<75,2,131,80,0,0,0,247,120,1,203,96,206,97,96,96,96,204,96,130,82,41,12,172,137,201,37,249,69,185,64,81,145,247,235,108,38,154,170,95,47,158,239,182,161,38,224,232,241,31,137,199,152,108,178,18,25,179,50,56,83,24,88,82,50,147,75,18,25,19,5,128,144,35,49,32,209,32,67,32,11,13,100,48,2,197,192,230,130,8,166,20,6,193,176,212,162,188,84,223,64,7,67,35,115,61,3,32,52,36,205,94,116,243,225,206,96,32,232,12,52,173,0,211,246,78,109>>
2023-02-11 23:29:42.819 [info] <0.228.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta1"
2023-02-11 23:29:42.828 [info] <0.238.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta2"
2023-02-11 23:29:42.830 [info] <0.247.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta3"
2023-02-11 23:29:42.832 [info] <0.256.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta4"
2023-02-11 23:29:42.834 [info] <0.265.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta5"
2023-02-11 23:29:42.837 [info] <0.274.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta6"
2023-02-11 23:29:42.846 [info] <0.283.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta7"
2023-02-11 23:29:42.849 [info] <0.292.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta8"
2023-02-11 23:29:42.852 [info] <0.301.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta9"
2023-02-11 23:29:42.858 [info] <0.310.0>@vmq_swc_db_leveldb:open_db:{269,13} Opening LevelDB SWC database at "./data/swc_meta/meta10"
2023-02-11 23:29:42.882 [info] <0.215.0>@vmq_metadata:start:{29,5} Try to start vmq_swc: ok
2023-02-11 23:29:42.907 [info] <0.323.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/1"
2023-02-11 23:29:42.908 [info] <0.324.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/2"
2023-02-11 23:29:42.909 [info] <0.325.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/3"
2023-02-11 23:29:42.910 [info] <0.326.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/4"
2023-02-11 23:29:42.911 [info] <0.327.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/5"
2023-02-11 23:29:42.913 [info] <0.328.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/6"
2023-02-11 23:29:42.914 [info] <0.329.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/7"
2023-02-11 23:29:42.915 [info] <0.330.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/8"
2023-02-11 23:29:42.916 [info] <0.331.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/9"
2023-02-11 23:29:42.917 [info] <0.332.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/10"
2023-02-11 23:29:42.919 [info] <0.333.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/11"
2023-02-11 23:29:42.920 [info] <0.334.0>@vmq_storage_engine_leveldb:open_db:{145,13} Opening LevelDB database at "./data/msgstore/12"
2023-02-11 23:29:42.938 [info] <0.215.0>@vmq_message_store:start:{29,5} Try to start vmq_generic_msg_store: ok
2023-02-11 23:29:43.157 [info] <0.422.0>@vmq_reg_trie:handle_info:{254,5} loaded 0 subscriptions into vmq_reg_trie
2023-02-11 23:29:43.159 [info] <0.226.0>@vmq_cluster:init:{163,5} cluster event handler 'vmq_cluster' registered
2023-02-11 23:29:43.176 [error] <0.438.0>@vmq_ranch_config:reconfigure_listeners_for_type:{269,13} can't reconfigure mqtts listener({127,0,0,1}, 1883) with Options [{max_connections,10000},{nr_of_acceptors,10},{mountpoint,[]},{depth,1},{eccs,[sect571r1,sect571k1,secp521r1,brainpoolP512r1,sect409k1,sect409r1,brainpoolP384r1,secp384r1,sect283k1,sect283r1,brainpoolP256r1,secp256k1,secp256r1,sect239k1,sect233k1,sect233r1,secp224k1,secp224r1,sect193r1,sect193r2,secp192k1,secp192r1,sect163k1,sect163r1,sect163r2,secp160k1,secp160r1,secp160r2]},{require_certificate,false},{tls_version,'tlsv1.2'},{use_identity_as_username,false},{allowed_protocol_versions,[3,4,131]},{allow_anonymous_override,false}] due to {already_started,<0.439.0>}
2023-02-12 00:01:07.534 [warning] <0.624.0>@vmq_mqtt5_fsm:connected:{819,13} client {[],<<"anon-2ha56hhQ43xLc3OLo/v3LHUz3WE=">>} with username undefined stopped due to keepalive expired
2023-02-12 00:01:07.535 [warning] <0.624.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to 'keep_alive_timeout'
2023-02-12 00:01:11.148 [warning] <0.641.0>@vmq_mqtt5_fsm:connected:{819,13} client {[],<<"anon-LnYtyKxY2W/lZfeFJs8cmOUvzeg=">>} with username undefined stopped due to keepalive expired
2023-02-12 00:01:11.148 [warning] <0.641.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to 'keep_alive_timeout'
2023-02-12 00:01:15.778 [warning] <0.577.0>@vmq_mqtt5_fsm:connected:{819,13} client {[],<<"anon-buwe+qoOw6onVSGzUITQBruqpos=">>} with username undefined stopped due to keepalive expired
2023-02-12 00:01:15.779 [warning] <0.577.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to 'keep_alive_timeout'
2023-02-12 00:22:58.908 [warning] <0.725.0>@vmq_mqtt5_fsm:connected:{819,13} client {[],<<"mqttx_80575925">>} with username <<>> stopped due to keepalive expired
2023-02-12 00:22:58.908 [warning] <0.725.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to 'keep_alive_timeout'
2023-02-12 00:23:05.074 [warning] <0.597.0>@vmq_mqtt5_fsm:connected:{819,13} client {[],<<"anon-lSLrqH1rFEb6lcVnIBxp+XKXWMM=">>} with username undefined stopped due to keepalive expired
2023-02-12 00:23:05.074 [warning] <0.597.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to 'keep_alive_timeout'
2023-02-12 00:25:29.693 [warning] <0.590.0>@vmq_mqtt5_fsm:connected:{819,13} client {[],<<"anon-fxpBfR+Mq26p36GmJKKxR+urYKQ=">>} with username undefined stopped due to keepalive expired
2023-02-12 00:25:29.693 [warning] <0.590.0>@vmq_ranch:teardown:{176,13} session stopped abnormally due to 'keep_alive_timeout'
